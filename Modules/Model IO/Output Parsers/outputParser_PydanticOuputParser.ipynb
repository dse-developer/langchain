{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259M-8OXmQD7"
      },
      "source": [
        "# PydanticOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ÌïÑÏàò ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò Î∞è openai api key Îì±Î°ù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "4Vahr4cWmPN6"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "86kvSCFwnI2s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]      = \"sk-*****************************************************\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "g36Xe7W83Zo2"
      },
      "outputs": [],
      "source": [
        "#Î™®Îç∏ ÏÉùÏÑ±\n",
        "model = ChatOpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "rGuoKB2D3VjG"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSIDFiAD35eO"
      },
      "source": [
        "### example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSy11wjO3dBW",
        "outputId": "1fb667a7-7031-4248-d0bb-647dfba4c51a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Joke(setup=\"Why couldn't the bicycle stand up by itself?\", punchline='Because it was two tired!')"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define your desired data structure.\n",
        "class Joke(BaseModel):\n",
        "    setup: str = Field(description=\"question to set up a joke\")\n",
        "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
        "\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "    @validator(\"setup\")\n",
        "    def question_ends_with_question_mark(cls, field):\n",
        "        if field[-1] != \"?\":\n",
        "            raise ValueError(\"Badly formed question!\")\n",
        "        return field\n",
        "\n",
        "\n",
        "# And a query intented to prompt a language model to populate the data structure.\n",
        "joke_query = \"Tell me a joke.\"\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=Joke)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "chain = prompt | model | parser\n",
        "\n",
        "chain.invoke({\"query\": joke_query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UsDFc-G38V-"
      },
      "source": [
        "### example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izthwoVh3pz-",
        "outputId": "c5f0ae94-177d-42d0-ff4b-119a377bb62a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Cast Away', 'Saving Private Ryan', 'Toy Story', 'The Green Mile', 'Apollo 13'])"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here's another example, but with a compound typed field.\n",
        "class Actor(BaseModel):\n",
        "    name: str = Field(description=\"name of an actor\")\n",
        "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
        "\n",
        "\n",
        "actor_query = \"Generate the filmography for a random actor.\"\n",
        "\n",
        "#pydantic ÌååÏÑú ÏÉùÏÑ±\n",
        "parser = PydanticOutputParser(pydantic_object=Actor)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "chain = prompt | model | parser\n",
        "\n",
        "chain.invoke({\"query\": actor_query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7YhdfQb3-Rd"
      },
      "source": [
        "### example 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_W2KyMU3_1-",
        "outputId": "e0953263-f5c6-40dd-dcda-3bea05df5d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"person\": \"jiwon Shin\",\n",
            "  \"email\": \"dunndunn@dunndunn.com\",\n",
            "  \"subject\": \"AI engineers and Robots are getting real\",\n",
            "  \"summary\": \"This week was mind-blowing with two insane demos - a coding AI that can build full apps autonomously and a super realistic robot that acts like us. Meet Devin - The World's First Autonomous AI Coding Engineer and Figure Unleashes Jaw-Dropping AI Robot in OpenAI Collab. Devin is a combination of multiple AI agents working together to perform tasks of a human programmer. It has achieved an unprecedented score of 13.86% in the SWE-Bench benchmark. Devin can complete coding jobs on Upwork, pass coding interviews at leading tech companies, fine-tune other language models, develop a browser extension, and build simple games. Devin is in a limited beta currently. The era of autonomous AI coding may be closer than we think.\",\n",
            "  \"date\": \"Mar 12, 2024\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "email_contents = \"\"\"\n",
        "From: jiwon Shin (dunndunn@dunndunn.com)\n",
        "To: duck Kim (duck@duck.com)\n",
        "Subject: \"AI engineers and Robots are getting real\n",
        "\n",
        "Welcome back, AI enthusiasts!\n",
        "This week was simply mind-blowing, with two insane demos dropping that had our jaws on the floor - a coding AI that can build full apps autonomously, and a super realistic robot that understands and acts just like us.\n",
        "In today‚Äôs email:\n",
        "‚Ä¢\tMeet Devin - The World's First Autonomous AI Coding Engineer\n",
        "‚Ä¢\tFigure Unleashes Jaw-Dropping AI Robot in OpenAI Collab\n",
        "‚Ä¢\tClaude 3 Pro or ChatGPT Plus: Which subscription is better?\n",
        "\n",
        "\n",
        "\n",
        "News\n",
        "Meet Devin - The World's First Autonomous AI Coding Engineer\n",
        "The startup Cognition has launched a groundbreaking new tool called Devin that is pushing the boundaries of AI-powered software development and taking the internet by storm.\n",
        "This isn't the first time we've seen language models that can write code - powerful tools like GitHub Copilot already exist. But what makes Devin truly special is its ability to autonomously build entire products from start to finish.\n",
        " \tCognition @cognition_labs\n",
        "\n",
        "\n",
        "Today we're excited to introduce Devin, the first AI software engineer.\n",
        "Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.\n",
        "Devin is‚Ä¶ twitter.com/i/web/status/1‚Ä¶\n",
        "\n",
        "\n",
        "\n",
        "Mar 12, 2024\n",
        "\n",
        "\n",
        "\n",
        "42.7K Likes   10.1K Retweets   3.97K Replies\n",
        "\n",
        "\n",
        "How Does Devin Work?\n",
        "Devin is essentially a combination of multiple AI agents working together to perform the tasks of a human programmer. It comprises an integrated development environment (IDE), a terminal to run and debug code, and a browser to search for documentation online and troubleshoot issues.\n",
        "Previous attempts at building such coding AI agents suffered from major limitations, frequent crashes, and bugs. It appears the team at Cognition has cracked the code on an underlying framework that seamlessly connects these various agents - succeeding where big tech companies have struggled.\n",
        "The exact model powering Devin remains undisclosed, leading to speculation that it could be GPT-4 or a customized fine-tuned version of another large language model.\n",
        "In the SWE-Bench benchmark, where an AI must autonomously solve real coding problems from open-source GitHub projects, Devin achieved an unprecedented score of 13.86%. For context, the previous high score was just 1.98% - a massive leap in capabilities.\n",
        "\n",
        "\n",
        "What Can Devin Do?\n",
        "üëâ Fully complete coding jobs found on Upwork\n",
        "\n",
        "üëâ Pass coding interviews at leading tech companies\n",
        "üëâ Fine-tune other language models\n",
        "\n",
        "üëâ Develop a browser extension\n",
        "\n",
        "üëâ Build simple games\n",
        "It's important to note that for now, Devin is in a limited beta with only a few developers having access. Once it opens up more broadly, we'll get to see many more real-world use cases and better understand the true impact.\n",
        "In my opinion, we still have a long road ahead before language models can entirely replace human programmers at tech companies. But Devin represents a breakthrough not just in AI-powered coding, but in the broader field of AI agents collaborating on complex tasks.\n",
        "This is definitely a development worth following closely as AI pushes further into the realm of software engineering. The era of autonomous AI coding may be closer than we think.\n",
        "\"\"\"\n",
        "\n",
        "class EmailSummary(BaseModel):\n",
        "     person: str = Field(description=\"Person who sent the email\")\n",
        "     email: str = Field(description=\"Email address of sender\")\n",
        "     subject: str = Field(description=\"Email subject\")\n",
        "     summary: str = Field(description=\"Text summarizing the body of the email\")\n",
        "     date: str = Field(description=\"Meeting date and time mentioned in the email body\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=EmailSummary)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "EMAIL CONTENTS:\n",
        "{email_contents}\n",
        "\n",
        "FORMAT:\n",
        "{format}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "prompt = prompt.partial(format=parser.get_format_instructions())\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"email_contents\": email_contents,\n",
        "        \"question\": \"Ïù¥Î©îÏùº ÎÇ¥Ïö©Ï§ë Ï£ºÏöî ÎÇ¥Ïö©ÏùÑ Ï∂îÏ∂úÌï¥ Ï£ºÏÑ∏Ïöî.\",\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
