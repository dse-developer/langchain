{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9fa23b62",
      "metadata": {
        "id": "9fa23b62"
      },
      "source": [
        "# ReAct Agent + OpenAI Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76dd6ad",
      "metadata": {},
      "source": [
        "#### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "354b1e04",
      "metadata": {
        "id": "354b1e04"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain-openai langchain_community langchain_experimental langchain-text-splitters tiktoken pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "525ba4ba",
      "metadata": {},
      "source": [
        "#### Openai api key ë“±ë¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "8U_lhAypNH9G",
      "metadata": {
        "id": "8U_lhAypNH9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-**********************************************************'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G7LgipcowSQz",
      "metadata": {
        "id": "G7LgipcowSQz"
      },
      "source": [
        "## 1.ReAct Agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGP4LnO6kSHN",
      "metadata": {
        "id": "qGP4LnO6kSHN"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bSKLXxA2b19F",
      "metadata": {
        "id": "bSKLXxA2b19F"
      },
      "source": [
        "#### Tavily Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "Q6fkh9pYcN3S",
      "metadata": {
        "id": "Q6fkh9pYcN3S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-***********************************************\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "T40PysHVQfaH",
      "metadata": {
        "id": "T40PysHVQfaH"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "#ì •ë‹µ 5ê°€ì§€ ì„¤ì •\n",
        "search = TavilySearchResults(k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "v1w3zvKEctOr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1w3zvKEctOr",
        "outputId": "681e7791-b2ce-49c0-fedf-4b25ba47ca31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://m.blog.naver.com/sh2553/223159521355',\n",
              "  'content': 'ì‚¬ì´ë“œ ë©”ë‰´ë¥¼ ë‹¤ì–‘í•˜ê²Œ íŒë§¤í•˜ê³  ìžˆì–´ ìž…ì´ ì¦ê²ë‹¤. ì ì‹¬ì‹œê°„ì— ë°©ë¬¸í•˜ë©´ ì›¨ì´íŒ…ì´ ìžˆì„ ì •ë„ë¡œ. ìœ ëª…í•˜ê³  ë§›ìžˆëŠ” ì¦‰ì„ ë–¡ë³¶ì´ ë§›ì§‘ì´ë¼. ì¡°ê¸ˆ ì´ë¥¸ì‹œê°„ í˜¹ì€ ì¡°ê¸ˆ ëŠ¦ê²Œ ë°©ë¬¸ì„ ì¶”ì²œ! ìž¬ë°©ë¬¸ ì§€ìˆ˜ : â­â­â­â­â­. â¬‡ï¸ë¹¨ê°•ë–¡ë³¶ì´ í›„ê¸° ë³´ëŸ¬ê°€ê¸°â¬‡ï¸. https://blog ...'},\n",
              " {'url': 'https://blackbear88.tistory.com/entry/ì–‘ìž¬ì–‘ìž¬ì‹œë¯¼ì˜ìˆ²-ì½”ìŠ¤íŠ¸ì½”-ê·¼ì²˜-Në²ˆì§¸-ë°©ë¬¸-ì¹´ë ˆ-ëˆê¹ŒìŠ¤-ë§›ì§‘-â€œì•„ë¥´ì½”â€ë‚´ëˆ-ë‚´ì‚°-ì†”ì§í›„ê¸°',\n",
              "  'content': 'ì–‘ìž¬/ì–‘ìž¬ì‹œë¯¼ì˜ìˆ² ì½”ìŠ¤íŠ¸ì½” ê·¼ì²˜ ë§‘ì€ êµ­ë¬¼ì´ ë§›ìžˆëŠ” ê³°íƒ• ë§›ì§‘ \"ë‚¨ë„ë‚˜ì£¼ê³°íƒ•\",ë‚´ëˆ ë‚´ì‚° ì†”ì§í›„ê¸° (359) 2023.09.22 ìž ì‹¤/ìž ì‹¤ìƒˆë‚´ ë¡¯ë°íƒ€ì›Œ ê³ ì†Œí•œ ì¹˜ì¦ˆë¥¼ í™œìš©í•œ ë¸ŒëŸ°ì¹˜ ë§›ì§‘ \"ì¹˜ì¦ˆë£¸&í…Œì´ìŠ¤íŒ…ë£¸\",ë‚´ëˆ ë‚´ì‚° ì†”ì§í›„ê¸° (349)'},\n",
              " {'url': 'https://blog.naver.com/PostView.nhn?blogId=abc204308&logNo=223241678694',\n",
              "  'content': 'ëª½ê±°ëŠ” ì–‘ìž¬ì‹œë¯¼ì˜ ìˆ²ì—ì„œ. ë„ë³´ë¡œëŠ” 15ë¶„ê±°ë¦¬ì— ìœ„ì¹˜í•˜ê³  ìžˆì–´! ì£¼ë³€ì— ì´ë§ˆíŠ¸, ì½”ìŠ¤íŠ¸ì½” ë“± í° ì‡¼í•‘ì„¼í„°ê°€ ìžˆì–´ì„œ. ë§ˆì„ë²„ìŠ¤ë„ ë‹¤ë‹ˆê³  ìžˆì–´! ì–‘ìž¬ì‹œë¯¼ì˜ìˆ²ì—­ ì¹´íŽ˜ì—ì„œ ì°¾ê¸° ì‰½ì§€ì•Šì€. ì£¼ì°¨ê°€ëŠ¥í•œ ì¹´íŽ˜ë¼ì„œ ì°¨ ê°€ì ¸ì˜¤ì‹œëŠ” ë¶„ë“¤ì€. íŽ¸í•˜ê²Œ ì¹´íŽ˜ ì´ìš©ì´ ê°€ëŠ¥í•  ê²ƒ ...'},\n",
              " {'url': 'https://www.costco.co.kr/store-finder/Yangjae',\n",
              "  'content': '06772. ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬ ì–‘ìž¬ëŒ€ë¡œ 159. (ì–‘ìž¬ë™ 217-6) ì „í™”ë²ˆí˜¸: 1899-9900. ì´ë©”ì¼: member@costcokr.com. ê¸¸ ì°¾ê¸°.'},\n",
              " {'url': 'https://moovitapp.com/index/ko/ëŒ€ì¤‘_êµí†µ-ì½”ìŠ¤íŠ¸ì½”_ì–‘ìž¬ì -ì„œìš¸ì‹œSeoul-site_8477366-1802',\n",
              "  'content': \"ì½”ìŠ¤íŠ¸ì½” ì–‘ìž¬ì  ê¹Œì§€ ê°€ìž¥ ê°€ê¹Œìš´ ì—­ì€ ì–´ë””ì¸ê°€ìš”? ì½”ìŠ¤íŠ¸ì½” ì–‘ìž¬ì  ì— ê°€ìž¥ ê°€ê¹Œìš´ ë…¸ì„ ë“¤ì€ : ì–‘ìž¬ì‹œë¯¼ì˜ìˆ² Yangjae Citizen's Forest ì€(ëŠ”) 611 ë¯¸í„° ê±°ë¦¬ì´ë©°, 9 ë¶„ ë„ë³´ê°€ ì†Œìš”ë©ë‹ˆë‹¤. ì–‘ìž¬2ë™ì£¼ë¯¼ì„¼í„°.ì–‘ìž¬ê½ƒì‹œìž¥ ì€(ëŠ”) 694 ë¯¸í„° ê±°ë¦¬ì´ë©°, 10 ë¶„ ë„ë³´ê°€ ì†Œìš”ë©ë‹ˆë‹¤.\"}]"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#í…ŒìŠ¤íŠ¸\n",
        "search.invoke(\"ì–‘ìž¬ ì‹œë¯¼ì˜ ìˆ²ì—ì„œ ê°€ìž¥ ê°€ê¹Œìš´ ì½”ìŠ¤íŠ¸ì½”ëŠ” ì–´ë””ì¸ê°€ìš”?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "id": "GT7lgfcsvqO4",
      "metadata": {
        "id": "GT7lgfcsvqO4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "id": "Kb8YlFe6vzLv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb8YlFe6vzLv",
        "outputId": "78f5d2bb-5a10-4f12-82bc-14d4759e29e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbMt0LVOwdZf",
      "metadata": {
        "id": "fbMt0LVOwdZf"
      },
      "source": [
        "### Construct the OpenAI Functions agent\n",
        "\n",
        "**create_openai_functions_agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "id": "dAKOSa8Bv0Dg",
      "metadata": {
        "id": "dAKOSa8Bv0Dg"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_openai_functions_agent, tool\n",
        "\n",
        "#í•¨ìˆ˜ ì—ì´ì „íŠ¸ ìƒì„±\n",
        "agent_tools = [search]\n",
        "agent = create_openai_functions_agent(llm, agent_tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "id": "yTcZ3LzNv85v",
      "metadata": {
        "id": "yTcZ3LzNv85v"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "#ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„±\n",
        "agent_executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "id": "FPMz0ILbv_7v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPMz0ILbv_7v",
        "outputId": "bf932639-b079-4809-e2e3-3f194e219e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#í…ŒìŠ¤íŠ¸\n",
        "agent_executor.invoke({\"input\": \"hi!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "id": "HBoH3pSnwB6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBoH3pSnwB6f",
        "outputId": "a993cff6-4464-490d-9052-c5564ee08974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': 'ëž­ì²´ì¸ ê³µì‹ í™ˆíŽ˜ì´ì§€ ì£¼ì†Œ'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.samsungsds.com/kr/insights/what-is-langchain.html', 'content': 'ì¸ê³µì§€ëŠ¥\\nëž­ì²´ì¸(LangChain)ì´ëž€ ë¬´ì—‡ì¸ê°€?\\nì¸ì‡„í•˜ê¸°\\nì´ ê¸€ì€ IDGì˜ ì•„í‹°í´ì„ ì „ìž¬í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.\\n ëž­ì²´ì¸ì€ ê°„ë‹¨í•˜ê³  í†µí•©ëœ APIë¥¼ ë…¸ì¶œí•˜ì—¬ ê¸°ë³¸ LLMì˜ êµ¬í˜„ ì„¸ë¶€ ì‚¬í•­ì„ ìš”ì•½í•˜ëŠ”ë°, ì´ APIë¥¼ í†µí•´ ê°œë°œìžë“¤ì€ ì½”ë“œë¥¼ í¬ê²Œ ë³€ê²½í•˜ì§€ ì•Šê³  ëª¨ë¸ì„ ì‰½ê²Œ êµì²´í•˜ê±°ë‚˜ ëŒ€ì²´í•  ìˆ˜ ìžˆë‹¤.\\n êµ¬ë…í•˜ê¸°\\nì¢‹ì•„ìš”\\nInfoWorld\\në‰´ìŠ¤ë ˆí„° êµ¬ë…ì‹ ì²­ â‘ \\xa0 ë°ì´í„° ì†ŒìŠ¤\\nì• í”Œë¦¬ì¼€ì´ì…˜ì´ LLMì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ PDF, ì›¹ íŽ˜ì´ì§€, CSV, ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì™€ ê°™ì€ ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìžˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ ë° ìƒìš© LLM, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤, ë°ì´í„° ì†ŒìŠ¤ ë° ìž„ë² ë”©ì— ëŒ€í•œ ì§€ì›ì€ ëž­ì²´ì¸ì„ ê°œë°œìžì—ê²Œ í•„ìˆ˜ì ì¸ ë„êµ¬ë¡œ ë§Œë“¤ê³  ìžˆë‹¤.\\n'}, {'url': 'https://www.langchain.com/', 'content': 'Join Discord\\nContribute on GitHub\\n5.3M\\nMonthly Downloads\\n67k\\nGithub Stars\\n1800+\\nContributors\\n34k+\\nApps Powered\\nReady to build?\\nGo To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nContact Sales\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter Chatbots\\nQ&A Over Docs\\nSummarization\\nCopilots\\nWorkflow Automation\\nDocument Analysis\\nCustom Search\\nHarness the powerâ€“and wrangle the complexityâ€“ of LLMs\\nGet from proof-of-concept to production on one platform\\nRely on a set of tools built especially for non-deterministic models\\nLeverage new cognitive architectures and battle-tested orchestration\\nThanks to our contributors and partners for making LangChain awesome\\nWhen you build with LangChain, you build alongside a community of developers advancing the frontier of whatâ€™s possible with LLMs.\\n ðŸ¦œðŸ”— LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\nðŸ¦œðŸ”— LangChain\\nðŸ¦œðŸ”— LangChain\\nLangChain Expression Language makes it easy to create custom chains.\\n Go To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nA complete set of powerful building blocks\\nA complete set of powerful building blocks\\n Try it out here\\nGet your LLM application from prototype to production\\nGet your LLM application from prototype to production\\nBuild context-aware, reasoning applications with LangChainâ€™s flexible abstractions and AI-first toolkit.\\n'}, {'url': 'https://m.blog.naver.com/ilovehandson/223124167133', 'content': '\\u200b\\nìŠ¤í‚¤ë§ˆ(4 í•­ëª©)\\nëª¨ë¸(3í•­ëª©)\\ní”„ë¡¬í”„íŠ¸(4í•­ëª©)\\nì¸ë±ìŠ¤(4í•­ëª©)\\në©”ëª¨ë¦¬(1í•­ëª©)\\nì²´ì¸(4í•­ëª©)\\nì—ì´ì „íŠ¸(4í•­ëª©)\\nìŠ¤í‚¤ë§ˆ\\nì´ ì„¹ì…˜ì—ì„œëŠ” ì½”ë“œë² ì´ìŠ¤ ì „ì²´ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ë³¸ ë°ì´í„° ìœ í˜•ê³¼ ìŠ¤í‚¤ë§ˆì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.\\n \\u200b\\në¬¸ì„œë¥¼ ë‹¤ìŒ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•©ë‹ˆë‹¤:\\n\\u200b\\nðŸ“„ï¸ ë„êµ¬(Tools)\\nì–¸ì–´ ëª¨ë¸ì´ ë‹¤ë¥¸ ë¦¬ì†ŒìŠ¤ì™€ ìƒí˜¸ ìž‘ìš©í•˜ëŠ” ë°©ì‹\\n\\u200b\\nì–¸ì–´ ëª¨ë¸ì´ í•¨ìˆ˜ì™€ ì‰½ê²Œ ìƒí˜¸ ìž‘ìš©í•  ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” í•¨ìˆ˜ì— ëŒ€í•œ dodream7@naver.com\\nì´ ë¸”ë¡œê·¸\\nì‹œë§¨í‹± ì»¤ë„\\nì¹´í…Œê³ ë¦¬ ê¸€\\nì¹´í…Œê³ ë¦¬\\nì´ ë¸”ë¡œê·¸\\nì‹œë§¨í‹± ì»¤ë„\\nì¹´í…Œê³ ë¦¬ ê¸€ \\u200b\\nì´ ë¬¸ì„œ ì„¹ì…˜ì€ ë„¤ ê°œì˜ ì„¹ì…˜ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤:\\n\\u200b\\nðŸ“„ï¸ í”„ë¡¬í”„íŠ¸ ê°’(PromptValue)\\nëª¨ë¸ì— ëŒ€í•œ ìž…ë ¥ì„ ë‚˜íƒ€ë‚´ëŠ” í´ëž˜ìŠ¤ìž…ë‹ˆë‹¤.\\n ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ëŠ” ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ê³ ,\\nì•¡ì…˜ê³¼ ì•¡ì…˜ ìž…ë ¥ì„ ë‹¤ì‹œ ë°›ê³ ,\\ní•´ë‹¹ ìž…ë ¥ìœ¼ë¡œ ì•¡ì…˜ì´ ì°¸ì¡°í•˜ëŠ” ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³ ,\\në„êµ¬ì˜ ì¶œë ¥ì„ ê°€ì ¸ì˜¨ ë‹¤ìŒ ëª¨ë“  ì •ë³´ë¥¼ ë‹¤ì‹œ ì—ì´ì „íŠ¸ë¡œ ì „ë‹¬í•˜ì—¬\\në‹¤ìŒ ì•¡ì…˜ì„ ê°€ì ¸ì˜¤ëŠ” ì¼ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.\\n'}, {'url': 'https://kudositdaily.tistory.com/entry/LangChain-ì´ˆë³´ìžë¥¼-ìœ„í•œ-ì™„ë²½-ê°€ì´ë“œ', 'content': 'íƒœê·¸\\nê´€ë ¨ê¸€\\nê³µì§€ì‚¬í•­\\nDesigned by í‹°ìŠ¤í† ë¦¬\\nÂ© Kakao Corp.\\ní‹°ìŠ¤í† ë¦¬íˆ´ë°” Kudos IT Daily\\nLangChain - ì´ˆë³´ìžë¥¼ ìœ„í•œ ì™„ë²½ ê°€ì´ë“œ\\nLangChain - ì´ˆë³´ìžë¥¼ ìœ„í•œ ì™„ë²½ ê°€ì´ë“œ\\ní­ë°œì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” LLM í”Œëž«í¼\\nì•ˆë…•í•˜ì„¸ìš”. Github ì €ìž¥ì†Œì˜ Starì˜ ì¶”ì„¸ë¥¼ ë³¼ ìˆ˜ ìžˆëŠ” Star History í™ˆíŽ˜ì´ì§€ë¥¼ í†µí•´ ëž­ì²´ì¸ ì €ìž¥ì†Œì˜ Starì˜ ì¶”ì„¸ë¥¼ ë³´ë©´ ì´ë¯¸ 60kë¥¼ ë„˜ì–´ì„œ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë³´ì—¬ë“œë¦° ì˜ˆì œëŠ” ë‹¨íŽ¸ì ì¸ ì˜ˆì œì´ê³ , ëž­ì²´ì¸ì„ ê²€ìƒ‰í•´ ë³´ì‹œë©´ ëž­ì²´ì¸ì„ í™œìš©í•œ ë‹¤ì–‘í•œ ì–´í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ë¡€ë¥¼ ì‚´íŽ´ë³´ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n ì´ëŸ¬í•œ ëª¨ë“ˆë“¤ì„ ìž˜ ì‚¬ìš©í•œë‹¤ë©´ ì›í•˜ëŠ” ê¸°ëŠ¥ë“¤ì„ ì²´ì¸ì²˜ëŸ¼ ì—®ì–´ì„œ ë‹¤ì–‘í•œ ì–´í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\\n'}, {'url': 'https://ko.wikipedia.org/wiki/ëž­ì²´ì¸', 'content': 'ëž­ì²´ì¸(LangChain)ì€ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ì„ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±ì„ ë‹¨ìˆœí™”í•˜ë„ë¡ ì„¤ê³„ëœ í”„ë ˆìž„ì›Œí¬ì´ë‹¤. ì–¸ì–´ ëª¨ë¸ í†µí•© í”„ë ˆìž„ì›Œí¬ë¡œì„œ ëž­ì²´ì¸ì˜ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë¬¸ì„œ ë¶„ì„ ë° ìš”ì•½ , ì±—ë´‡ , ì½”ë“œ ë¶„ì„ ì„ í¬í•¨í•˜ì—¬ ì¼ë°˜ì ì¸ ì–¸ì–´ ëª¨ë¸ì˜ ì‚¬ìš© ì‚¬ë¡€ì™€ í¬ê²Œ ...'}]\u001b[0m\u001b[32;1m\u001b[1;3mëž­ì²´ì¸ì˜ ê³µì‹ í™ˆíŽ˜ì´ì§€ ì£¼ì†ŒëŠ” [https://www.langchain.com/](https://www.langchain.com/) ìž…ë‹ˆë‹¤.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "ëž­ì²´ì¸ì˜ ê³µì‹ í™ˆíŽ˜ì´ì§€ ì£¼ì†ŒëŠ” [https://www.langchain.com/](https://www.langchain.com/) ìž…ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "#í…ŒìŠ¤íŠ¸\n",
        "result = agent_executor.invoke(\n",
        "    {\"input\": \"ëž­ì²´ì¸ì˜ ê³µì‹ í™ˆíŽ˜ì´ì§€ ì£¼ì†Œë¥¼ ì•Œë ¤ì¤˜ìš”\"}\n",
        ")\n",
        "\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N5LXGmXI5q6N",
      "metadata": {
        "id": "N5LXGmXI5q6N"
      },
      "source": [
        "**Create tool**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "Ac1ICsrZ5uNG",
      "metadata": {
        "id": "Ac1ICsrZ5uNG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def multiply(first_int: int, second_int: int) -> int:\n",
        "    \"\"\"Multiply two integers together.\"\"\"\n",
        "    return first_int * second_int\n",
        "\n",
        "@tool\n",
        "def add(first_int: int, second_int: int) -> int:\n",
        "    \"Add two integers.\"\n",
        "    return first_int + second_int\n",
        "\n",
        "\n",
        "@tool\n",
        "def exponentiate(base: int, exponent: int) -> int:\n",
        "    \"Exponentiate the base to the exponent power.\"\n",
        "    return base**exponent\n",
        "\n",
        "\n",
        "tools = [multiply, add, exponentiate]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c-qm5tW9xkWE",
      "metadata": {
        "id": "c-qm5tW9xkWE"
      },
      "source": [
        "**create_openai_tool_agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "id": "kxQfH5CZxE12",
      "metadata": {
        "id": "kxQfH5CZxE12"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "\n",
        "tool_agent = create_openai_tools_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "id": "-Ff8UPr1x7JY",
      "metadata": {
        "id": "-Ff8UPr1x7JY"
      },
      "outputs": [],
      "source": [
        "#íˆ´ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„±\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "id": "5xra0PSsx-ev",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xra0PSsx-ev",
        "outputId": "12f2e346-38e0-460f-d494-501bcbc45327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': 'LangChain'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.langchain.com/langchain', 'content': 'Augment the power\\nof\\xa0LLMs with your data\\nLangChain helps connect LLMs to your companyâ€™s private sources\\nof data and APIs to create context-aware, reasoning applications.\\n Our Methods\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. The largest community building the future of LLM apps\\nLangChainâ€™s flexible abstractions and AI-first toolkit make it\\xa0the\\xa0#1\\xa0choice for developers when building with GenAI.\\n Why choose LangChain?\\nLangChain is easy to get started with and\\xa0gives\\xa0you choice, flexibility, and power as\\xa0you scale.\\n Get customizability and control with a durable runtime baked in\\nLangChain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.'}, {'url': 'https://github.com/langchain-ai/langchain', 'content': 'About\\nâš¡ Building applications with LLMs through composability âš¡\\nResources\\nLicense\\nCode of conduct\\nSecurity policy\\nStars\\nWatchers\\nForks\\nReleases\\n291\\nPackages\\n0\\nUsed by 39k\\nContributors\\n1,848\\nLanguages\\nFooter\\nFooter navigation Latest commit\\nGit stats\\nFiles\\nREADME.md\\nðŸ¦œï¸ðŸ”— LangChain\\nâš¡ Building applications with LLMs through composability âš¡\\nLooking for the JS/TS library? âš¡ Building applications with LLMs through composability âš¡\\nLicense\\nlangchain-ai/langchain\\nName already in use\\nUse Git or checkout with SVN using the web URL.\\n ðŸ“– Documentation\\nPlease see here for full documentation, which includes:\\nðŸ’ Contributing\\nAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.\\n What can you build with LangChain?\\nâ“ Retrieval augmented generation\\nðŸ’¬ Analyzing structured data\\nðŸ¤– Chatbots\\nAnd much more!'}, {'url': 'https://www.langchain.com/', 'content': 'Join Discord\\nContribute on GitHub\\n5.3M\\nMonthly Downloads\\n67k\\nGithub Stars\\n1800+\\nContributors\\n34k+\\nApps Powered\\nReady to build?\\nGo To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nContact Sales\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter Chatbots\\nQ&A Over Docs\\nSummarization\\nCopilots\\nWorkflow Automation\\nDocument Analysis\\nCustom Search\\nHarness the powerâ€“and wrangle the complexityâ€“ of LLMs\\nGet from proof-of-concept to production on one platform\\nRely on a set of tools built especially for non-deterministic models\\nLeverage new cognitive architectures and battle-tested orchestration\\nThanks to our contributors and partners for making LangChain awesome\\nWhen you build with LangChain, you build alongside a community of developers advancing the frontier of whatâ€™s possible with LLMs.\\n ðŸ¦œðŸ”— LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\nðŸ¦œðŸ”— LangChain\\nðŸ¦œðŸ”— LangChain\\nLangChain Expression Language makes it easy to create custom chains.\\n Go To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nA complete set of powerful building blocks\\nA complete set of powerful building blocks\\n Try it out here\\nGet your LLM application from prototype to production\\nGet your LLM application from prototype to production\\nBuild context-aware, reasoning applications with LangChainâ€™s flexible abstractions and AI-first toolkit.\\n'}, {'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}, {'url': 'https://www.ibm.com/topics/langchain', 'content': 'Applications made with LangChain provide great utility for a variety of use cases, from straightforward question-answering and text generation tasks to more complex solutions that use an LLM as a â€œreasoning engine.â€\\nTrain, validate, tune and deploy generative AI, foundation models and machine learning capabilities with ease and build AI applications in a fraction of the time with a fraction of the data.\\n When building a chain for an agent, inputs include:\\nDespite their heralded power and versatility, LLMs have important limitations: namely, a lack of up-to-date information, a lack of domain-specific expertise and a general difficulty with math.\\nLangChain tools\\xa0(link resides outside ibm.com) are a set of functions that empower LangChain agents to interact with real-world information in order to expand or improve the services it can provide. Launched by Harrison Chase in October 2022, LangChain enjoyed a meteoric rise to prominence: as of June 2023, it was the single fastest-growing open source project on Github.1 Coinciding with the momentous launch of OpenAIâ€™s ChatGPT the following month, LangChain has played a significant role in making generative AI more accessible to enthusiasts in the wake of its widespread popularity.\\n Reimagine how you work with\\xa0AI: our diverse, global team of more than 20,000 AI\\xa0experts can help you quickly and confidently\\xa0design and scale AI and automation across your\\xa0business, working across our own IBM\\xa0watsonx\\xa0technology\\xa0and an open ecosystem of partners to deliver any\\xa0AI model, on any cloud, guided by ethics and trust.\\n While itâ€™s the GPT model that interprets the userâ€™s input and composes a natural language response, itâ€™s the application that (among other things) provides an interface for the user to type and read and a UX design that governs the chatbot experience.'}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a platform that helps connect Large Language Models (LLMs) to private sources of data and APIs to create context-aware, reasoning applications. It provides developers with flexible abstractions and an AI-first toolkit to build with GenAI. LangChain offers customizability, control, and a durable runtime, making it easy to get started and scale applications. LangChain Expression Language (LCEL) allows developers to build apps in a composable way and customize them as needed. LangChain was launched in October 2022 as an open-source project and has gained popularity for its capabilities in document analysis and summarization, chatbots, and code analysis. It has integrations with various systems and tools to support a wide range of use cases.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is LangChain?',\n",
              " 'output': 'LangChain is a platform that helps connect Large Language Models (LLMs) to private sources of data and APIs to create context-aware, reasoning applications. It provides developers with flexible abstractions and an AI-first toolkit to build with GenAI. LangChain offers customizability, control, and a durable runtime, making it easy to get started and scale applications. LangChain Expression Language (LCEL) allows developers to build apps in a composable way and customize them as needed. LangChain was launched in October 2022 as an open-source project and has gained popularity for its capabilities in document analysis and summarization, chatbots, and code analysis. It has integrations with various systems and tools to support a wide range of use cases.'}"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#í…ŒìŠ¤íŠ¸\n",
        "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "id": "uNfBVMyX50JO",
      "metadata": {
        "id": "uNfBVMyX50JO"
      },
      "outputs": [],
      "source": [
        "# Choose the LLM that will drive the agent\n",
        "# Only certain models support this\n",
        "model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "# Construct the OpenAI Tools agent\n",
        "agent = create_openai_tools_agent(model, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "id": "bsJ2vqZ16Gln",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsJ2vqZ16Gln",
        "outputId": "c05496ce-4b01-4d07-a502-fa5072563168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3, 'exponent': 5}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'first_int': 12, 'second_int': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3mAre followup questions needed here: No.\n",
            "Intermediate answer: 3 to the fifth power is 243. The sum of twelve and three is 15.\n",
            "Follow up: Multiply 243 by 15.\n",
            "Intermediate answer: 243 multiplied by 15 is 3645.\n",
            "Follow up: Square 3645.\n",
            "Intermediate answer: The square of 3645 is 13302025.\n",
            "So the final answer is: 13302025\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result',\n",
              " 'output': 'Are followup questions needed here: No.\\nIntermediate answer: 3 to the fifth power is 243. The sum of twelve and three is 15.\\nFollow up: Multiply 243 by 15.\\nIntermediate answer: 243 multiplied by 15 is 3645.\\nFollow up: Square 3645.\\nIntermediate answer: The square of 3645 is 13302025.\\nSo the final answer is: 13302025'}"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result\"\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
